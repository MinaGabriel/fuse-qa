{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b19731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/MinaGabriel/fuse-qa.git\n",
    "# %cd /content/fuse-qa\n",
    "# export HF_TOKEN=\n",
    "# ! pip install -e . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a8cb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama_Meta-Llama-3-8B-FUSEQA_20260219-1011\n",
      "GPUs: 1\n",
      "Logged in to Hugging Face.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import json\n",
    "from fuseqa import *\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "# runr> export HF_TOKEN=your_token_here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B\"\n",
    "#MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "#MODEL_NAME = \"google/gemma-2-2b-it\" \n",
    "#MODEL_NAME = \"openai/gpt-oss-20b\"\n",
    "# Types: \n",
    "#   - PARAMETRIC:\n",
    "#   - FUSEQA:\n",
    "#   - FUSEQA-SRE:  \n",
    "RUN_TYPE = \"FUSEQA\"\n",
    "USE_CONTEXT = RUN_TYPE in (\"FUSEQA\", \"FUSEQA-SRE\")\n",
    "print(hf_model_to_filename(MODEL_NAME + \"-\" + RUN_TYPE))\n",
    "print(\"GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "if token:\n",
    "    login(token=token)\n",
    "    print(\"Logged in to Hugging Face.\")\n",
    "else:\n",
    "    print(\"HF_TOKEN not set.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6730b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680b9f06d6144302b11ebaca7b36ff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "Single-device load (no map needed)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "\n",
    "if hasattr(model, \"hf_device_map\"):\n",
    "    print(\"Device map:\", model.hf_device_map)\n",
    "else:\n",
    "    print(\"Single-device load (no map needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070af6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"MinaGabriel/popqa-with-retrieval-20\")[\"test\"].select(range(125))\n",
    "ds = load_dataset(\"MinaGabriel/popqa-with-retrieval-20\")[\"test\"]\n",
    "len(ds)\n",
    "\n",
    "TOP_K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a17d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating + Evaluating: 100%|██████████| 14267/14267 [55:24<00:00,  4.29it/s, ALL_EM=0.4669, Long_Tail=0.4682, Infrequent=0.4271, Frequent=0.6087]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: meta-llama_Meta-Llama-3-8B-FUSEQA_20260219-1014.report.txt | Time=3324.05s | ALL=0.4670 | LONG-TAIL=0.4682 | INFREQUENT=0.4272 | FREQUENT=0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "import time\n",
    "\n",
    "def run_popqa_eval(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    write_outputs=False,\n",
    "    groups=(\"ALL\", \"LONG-TAIL\", \"INFREQUENT\", \"FREQUENT\"),\n",
    "):\n",
    "    start_time = time.time()  #START TIMER\n",
    "\n",
    "    counts  = {g: 0 for g in groups}\n",
    "    em_hits = {g: 0 for g in groups}\n",
    "\n",
    "    def update_metrics(tier, em):\n",
    "        counts[\"ALL\"] += 1\n",
    "        em_hits[\"ALL\"] += em\n",
    "\n",
    "        if tier in counts:\n",
    "            counts[tier] += 1\n",
    "            em_hits[tier] += em\n",
    "\n",
    "    def current_scores():\n",
    "        return {\n",
    "            \"ALL_EM\":     safe_div(em_hits[\"ALL\"],        counts[\"ALL\"]),\n",
    "            \"Long_Tail\":  safe_div(em_hits[\"LONG-TAIL\"],  counts[\"LONG-TAIL\"]),\n",
    "            \"Infrequent\": safe_div(em_hits[\"INFREQUENT\"], counts[\"INFREQUENT\"]),\n",
    "            \"Frequent\":   safe_div(em_hits[\"FREQUENT\"],   counts[\"FREQUENT\"]),\n",
    "        }\n",
    "\n",
    "    file_name = hf_model_to_filename(MODEL_NAME + \"-\" + RUN_TYPE)\n",
    "    outfile   = file_name + \".jsonl\"\n",
    "\n",
    "    context_manager = open(outfile, \"w\", encoding=\"utf-8\", buffering=1) if write_outputs else nullcontext()\n",
    "\n",
    "    progress_bar = tqdm.tqdm(\n",
    "        total=len(ds),\n",
    "        desc=\"Generating + Evaluating\",\n",
    "        dynamic_ncols=True,\n",
    "    )\n",
    "\n",
    "    model_device = next(model.parameters()).device\n",
    "\n",
    "    with context_manager as writer:\n",
    "        for i in range(len(ds)):\n",
    "\n",
    "            ex = {k: ds[k][i] for k in ds.column_names}\n",
    "\n",
    "            q      = ex[\"question\"]\n",
    "            s_pop  = int(ex.get(\"s_pop\", 0))\n",
    "            tier   = tier_from_spop(s_pop)\n",
    "\n",
    "            gold = parse_list(ex.get(\"possible_answers\"))\n",
    "            gold_norm_set = {norm(g) for g in gold if norm(g)}\n",
    "\n",
    "            retrieved = ex.get(\"retrieved_docs\") or []\n",
    "            context   = build_context(retrieved, k=TOP_K) if USE_CONTEXT else \"\"\n",
    "\n",
    "            pred = ask_llm_generate(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                q,\n",
    "                context,\n",
    "                use_context=USE_CONTEXT,\n",
    "                device=model_device\n",
    "            )\n",
    "\n",
    "            pred_norm = norm(pred)\n",
    "            em = int(pred_norm in gold_norm_set) if gold_norm_set else 0\n",
    "\n",
    "            update_metrics(tier, em)\n",
    "\n",
    "            if write_outputs:\n",
    "                record = {\n",
    "                    \"i\": i,\n",
    "                    \"s_pop\": s_pop,\n",
    "                    \"tier\": tier,\n",
    "                    \"question\": q,\n",
    "                    \"gold\": gold,\n",
    "                    \"pred\": pred,\n",
    "                    \"em\": em,\n",
    "                }\n",
    "                write_record(writer, record)\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress_bar.set_postfix({k: f\"{v:.4f}\" for k, v in current_scores().items()})\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    total_time = time.time() - start_time  #END TIMER\n",
    "\n",
    "    return counts, em_hits, file_name, total_time\n",
    "\n",
    "\n",
    "# RUN\n",
    "counts, em_hits, file_name, total_time = run_popqa_eval(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    write_outputs=False\n",
    ")\n",
    "\n",
    "generate_report(\n",
    "    counts,\n",
    "    em_hits,\n",
    "    file_name,\n",
    "    model_name=MODEL_NAME,\n",
    "    run_type=RUN_TYPE,\n",
    "    total_time=total_time,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
